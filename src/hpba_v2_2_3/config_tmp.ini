[CLASSIFIER]
# mandatory
# - Please specify full path of classifer
classifierPath = D:/TSDV/hpba/src/classifier/pretrained_models/cifar_lenet.h5


[DATA]
# mandatory
# useDataFolder: Whether load data from folder of images or '.npy' file. Value: 1: load data from folder, 0: load data from '.npy' file

useDataFolder = 1
dataFolder = D:\training_data

# - Please specify full path of data if useDataFolder = 0
trainingDataPath = /media/dominhkha/D/AdvGeneration/data/mnist/mnist_training.npy
labelDataPath = /media/dominhkha/D/AdvGeneration/data/mnist/mnist_label.npy



[ATTACK]
# mandatory
# originalClass: origin class for attacking
#               Value is ranged from 0 to (number of class)
originalLabel = 9


# mandatory
# Please specify one of the following arguments:
# targetClass: fool classifier predicts as 'targetLabel' if 'targetClass' is specified. 'targetPosition' is ignored
#              Value is ranged from 0 to (number of class - 1) except original class. Default:-1
# targetPosition: position of 'targetLabel' in ordered list of label. If 'targetLabel' is not specified (value = -1), 'targetPosition' is used to determine 'targetPosition'
#              Value if ranged from 2 to (number of class). Default: 2
targetLabel = -1
targetPosition = 2



# optional
# recoverSpeed: number of feature to recover for each prediction (recoverSpeed * L0)
#               Default: 0.1
recoverSpeed = 0.1

#optional
# weight: trade-off between quality and success rate.
#         The greater 'weight', the greater success rate and the less quality, and vice versa. Default: 0.05
weight = 0.05

#optional
# numberDataToAttack: number of data for generating advs. Default: 1000
numberDataToAttack = 1000

#optional
# numberDataToTrainAutoencoder: number of data for training autoencoder. Default: 1000
numberDataToTrainAutoencoder = 1000

#optinal
# maxNumberAdvsToOptimize: number of advs need to be optimized in term of quality. Default: -1 as all generated advs will be optimized
#

maxNumberAdvsToOptimize = -1

epoch_to_optimize = 10
batch_to_optimize = 500



